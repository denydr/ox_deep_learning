{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c7af4d-004d-4f2f-997d-cc671a985b19",
   "metadata": {},
   "source": [
    "# Text generation with LSTM\n",
    "This notebook contains the code samples found in Chapter 8, Section 1 of Deep Learning with Python. Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcba382-e577-4747-b903-b818cf4acdcb",
   "metadata": {},
   "source": [
    "## Implementing character-level LSTM text generation\n",
    "Let's put these ideas in practice in a Keras implementation. The first thing we need is a lot of text data that we can use to learn a language model. You could use any sufficiently large text file or set of text files -- Wikipedia, the Lord of the Rings, etc. In this example we will use some of the writings of Nietzsche, the late-19th century German philosopher (translated to English). The language model we will learn will thus be specifically a model of Nietzsche's writing style and topics of choice, rather than a more generic model of the English language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f488c786-1f1a-4d07-b0df-bd4305fa60a9",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "Let's start by downloading the corpus and converting it to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a0e005-7db5-4a62-9f1f-77098171e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import certifi\n",
    "import urllib\n",
    "\n",
    "ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
    "\n",
    "response = urllib.request.urlopen('https://s3.amazonaws.com/text-datasets/nietzsche.txt', context=ssl_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf808e2e-1efe-4d99-a461-b5e70549600d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "\u001b[1m600901/600901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46c4f3-cec7-48f0-9586-66aba3873cbf",
   "metadata": {},
   "source": [
    "Next, we will extract partially-overlapping sequences of length maxlen, one-hot encode them and pack them in a 3D Numpy array x of shape (sequences, maxlen, unique_characters). Simultaneously, we prepare a array y containing the corresponding targets: the one-hot encoded characters that come right after each extracted sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4227ddc9-0780-44fc-a03d-3001e1dfeb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 200278\n",
      "Unique characters: 57\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c68e33e-3d48-4640-85a2-ba40fc46e619",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "Our network is a single LSTM layer followed by a Dense classifier and softmax over all possible characters. But let us note that recurrent neural networks are not the only way to do sequence data generation; 1D convnets also have proven extremely successful at it in recent times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d915a5-bb32-4cc6-a8e3-a301b49842a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dd/PycharmProjects/ox_deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d37e73-f01b-4bbc-b6dd-76a5d909e195",
   "metadata": {},
   "source": [
    "Since our targets are one-hot encoded, we will use categorical_crossentropy as the loss to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ab0ac2a-e7ae-4fa2-b181-a4ec77500bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63df6970-7fea-49b4-ae66-dfe5f1959fa5",
   "metadata": {},
   "source": [
    "## Training the language model and sampling from it\n",
    "Given a trained model and a seed text snippet, we generate new text by repeatedly:\n",
    "\n",
    "1) Drawing from the model a probability distribution over the next character given the text available so far\n",
    "2) Reweighting the distribution to a certain \"temperature\"\n",
    "3) Sampling the next character at random according to the reweighted distribution\n",
    "4) Adding the new character at the end of the available text\n",
    "\n",
    "\n",
    "This is the code we use to reweight the original probability distribution coming out of the model, and draw a character index from it (the \"sampling function\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff819a1-4e47-4eb3-bf27-0eae380c4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb3573-38a5-49de-bc25-a4a830df0c2b",
   "metadata": {},
   "source": [
    "Finally, this is the loop where we repeatedly train and generated text. We start generating text using a range of different temperatures after every epoch. This allows us to see how the generated text evolves as the model starts converging, as well as the impact of temperature in the sampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0447d44-ef32-455d-943c-2a09fb89478d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 56ms/step - loss: 2.3070\n",
      "--- Generating with seed: \"ler, by himself too oft self-wrung?\n",
      "     hindering too oft m\"\n",
      "------ temperature: 0.2\n",
      "ler, by himself too oft self-wrung?\n",
      "     hindering too oft mankind the such the the such a contemption of the such a mortations of the such is interness of the such the stame and man it is the all the such the suphication of the such the the will the the more and every and interlong the still and interman and interlong in the stame the such the stame the stance of the stame the such of the the such of the the such the such the manker of the the such intant\n",
      "------ temperature: 0.5\n",
      "h of the the such the such the manker of the the such intanter the will the wild it where where everything in the\n",
      "one from himself and endication of himself is a man as the stime where is the protice in contiman in the freemon and interest of the suppenict of are contern some are the the such the seligion every which all such one in the the sunderful in the waster of the among the strong the thing have\n",
      "in\n",
      "the stame of hist and such a freem be into\n",
      "the such\n",
      "------ temperature: 1.0\n",
      " have\n",
      "in\n",
      "the stame of hist and such a freem be into\n",
      "the such ammankism id, thensing fits of pastenedne a\n",
      "what \"the divild of wimly the light all discurned: of\n",
      "thest a  m the the imsingic pht cereangeatery\"--is bejuring and him is dose in hist their gon the reark and , them is slint time is 5eatoance xampressh, and prother the truther--is mightr--                imu!dings of plecies should tho o) oldupients onedly a rmadsaate (il wherm for the nee a world  \n",
      "------ temperature: 1.2\n",
      "ldupients onedly a rmadsaate (il wherm for the nee a world  no \"bid, is orderatily, humo\n",
      "cruphtence swant frie much\n",
      "that mutilo 8igainecs the sw! trays hrush--if begewulal\n",
      "wrutiscent couthrus, himpery crablichts sowe thick jud imphhendily wild which8abuleny dociousis as conscrom,binesy of mon wolld. unitamess\"\n",
      "\n",
      "\n",
      "!\n",
      " nands of-sarn thy refisesged onjecte \"manity plain lig to well mocesfity of\n",
      "a nobxe is\n",
      "arly uncosdicilut anis\"u--alwabting to ; himhe apere wol\n",
      "epoch 2\n",
      "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 60ms/step - loss: 1.6580\n",
      "--- Generating with seed: \"ping,\n",
      "reaches its climax--in short, that necessity and \"free\"\n",
      "------ temperature: 0.2\n",
      "ping,\n",
      "reaches its climax--in short, that necessity and \"free of the self-comes and a comparation of the comparation of the far the comprehaments and the comparation of the comparation of the same the supertain the comparation and the comparation of the supertanity and the supertain the scholled to a states of the comparation of the comparation of the comprehaments of the comparation of the comparation of the comprehament the supertain the comparation of th\n",
      "------ temperature: 0.5\n",
      "tion of the comprehament the supertain the comparation of the prestions of the trued became and and supertain of the companity the compathy of the have the charment and philosophy of the restence of the truth and decessity of the same it that the that the most part of the finding in the comparations has has concerning and\n",
      "and the charment that the propression of the spirest of the compaint far this find something it were of the fancther successed there is \n",
      "------ temperature: 1.0\n",
      "s find something it were of the fancther successed there is it rough to nob that macker of the wast uster, prehap_ of these\n",
      "arted destived and desplications phancoloped\n",
      "man thosibol of the \"whinf,\n",
      "stoopitial and hencely in best it and\n",
      "like but inlouble belies and and came-neal of mane\" at it which perprestopanedey,\n",
      "will of the\n",
      "han and superthing\n",
      "of adnature-the for is not\n",
      "pretament recatements\n",
      "upines has wencer manger, when without\n",
      "anful with the forment\n",
      "e\n",
      "------ temperature: 1.2\n",
      "nes has wencer manger, when without\n",
      "anful with the forment\n",
      "equal for an accerted and victity uty flow pighenise ensuch upharcy ankids\" there harn course, hume, if.3ande no deta-der wholaplys of feeling gyefal in their opinio nacuscery.\n",
      ".0= that wull consciing happy.; awaye selfaris, mind\n",
      "impaints, amote, foun or and not meaned worder---they age, thooder\n",
      "ffeels see. the fepuleanyëken it 3cepore: worqoring the will thaterentseretuen-aminatidicication of paw.\n",
      "epoch 3\n",
      "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 61ms/step - loss: 1.5400\n",
      "--- Generating with seed: \"the\n",
      "future will say, perhaps. one must renounce the bad tast\"\n",
      "------ temperature: 0.2\n",
      "the\n",
      "future will say, perhaps. one must renounce the bad taster of the such a destruction of the constinction of the same the constinction of the world the suffer to the such a the soul as the prodection of the such a the soul as a states of the same the soul of the same the sufferent of the moral precert and such a the soul and is at the same to the sense of the such as a man what is to the constantly and soul as a delight to the same the suffer of the suc\n",
      "------ temperature: 0.5\n",
      "ntly and soul as a delight to the same the suffer of the such an eposing man was all that which was to be a sense, they german proper and the goden delights that the science, of a done conscience of prood to arady to me such a souls of man who sought the philosopher and life in the interpretation is operates the constant and with the world be the\n",
      "interners of the man this is morality, as so the formuling and groups to a distaint, the constince of the dange\n",
      "------ temperature: 1.0\n",
      "rmuling and groups to a distaint, the constince of the dangerous, to deceas\n",
      "the corezrion love to when when himders is toceress to lapse,, by cotutious is a\n",
      "this\n",
      "contemness, that a mins is: is also the is were, they a7ught the beare ogs endumatice to the\n",
      "saveris through to be soul amove\n",
      "and this.  hese cultual and as of world to embed\n",
      "to perhaps denable, desist, the of iforn as i as\n",
      "cibling expressary\n",
      "from such as\n",
      "a all canteking. af that who bions, are   \n",
      "------ temperature: 1.2\n",
      "sary\n",
      "from such as\n",
      "a all canteking. af that who bions, are   evety maves certain'ss actudnig, anothergkanderation is believed they have till, sheie delignnes, and\n",
      "is musfown that to the harding its\n",
      "befinglems of sentimable, of zilitived\n",
      "i ariught (raturfwh instinct probit cases, way[hirrly who is degene\n",
      "oft iase science, the symbe arruilt towa, no gion as stuciziatist rading\n",
      "dyfeigs\n",
      "philosopher out\n",
      "and\n",
      "istem;tforalife--rengerstay and rebid ens ent;\n",
      "cturchab\n",
      "epoch 4\n",
      "\u001b[1m 596/1565\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 65ms/step - loss: 1.4740"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 60):\n",
    "    print('epoch', epoch)\n",
    "    # Fit the model for 1 epoch on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be14b5e-0692-4473-b09a-546dd9fd5050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c263b1cc-7b7f-4ba0-97e1-c51f82c83e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
